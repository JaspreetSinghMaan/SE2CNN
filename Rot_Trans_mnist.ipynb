{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    },
    "colab": {
      "name": "Rot_Trans_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxs_FWMtod0K",
        "colab_type": "text"
      },
      "source": [
        "*Jaspreet Singh, Punjabi University, Patiala (Punjab, India)*\n",
        "\n",
        "*28 April 2020* \n",
        "\n",
        "*The network is modified to be complete roto and tranlsation invariant by sticking with (5x5 and 1x1) SE(2) group convolutions all the way to the output layer, which would then provide a length 10 feature vector for each orientation. And then simply did a maximum projection over the orientations (tf.reduce_max) to get the maximal response for each bin, followed by a softmax.*\n",
        "\n",
        "*This program is orginally written by Erik J. Bekkers and Maxime W. Lafarge, Eindhoven University of Technology, the Netherlands*\n",
        "\n",
        "*8 June 2018*\n",
        "\n",
        "***\n",
        "\n",
        "*This DEMO was tested on a laptop with*:\n",
        "- *Windows as OS*\n",
        "- *Jupyter Notebook (version 5.5.0)*\n",
        "- *Python (version 3.5.5)*\n",
        "- *TensorFlow-GPU (versions 1.1 and higher)*\n",
        "- *An NVIDIA Quadro M1000M GPU*\n",
        "- *The following additional libraries installed for this demo to run: sklearn, scipy, and matplotlib*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLCsw1pUmGad",
        "colab_type": "code",
        "outputId": "dab35978-1157-4afe-9a18-5f21980e78a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "pip install tensorflow==1.15"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdZbuArFoits",
        "colab_type": "code",
        "outputId": "3513d5c5-19fb-44c9-9c7d-113f1b29dbe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#from google.colab import drive\n",
        "import sys\n",
        "#drive.mount('/content/drive')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/My Drive/SE2CNN-master/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMp33SZPod0P",
        "colab_type": "text"
      },
      "source": [
        "# Basic usage of the se2cnn library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtUZLiPQod0S",
        "colab_type": "text"
      },
      "source": [
        "This jupyter demo will contain the basic usage examples of the se2cnn library with applications to digit recognition in the MNIST dataset. The se2cnn library contains 3 main layers (check the useage via *help(se2cnn.layers.z2_se2n)*):\n",
        "- **z2_se2n**: a lifting layer from 2D tensor to SE(2) tensor\n",
        "- **se2n_se2n**: a group convolution layer from SE(2) tensor to SE(2) tensor\n",
        "- **spatial_max_pool**: performs 2x2 spatial max-pooling of the spatial axes\n",
        "\n",
        "The following functions are used internally, but may be of interest as well:\n",
        "- **rotate_lifting_kernels**: rotates the raw 2D lifting kernels (output is a set of rotated kernels)\n",
        "- **rotate_gconv_kernels**: rotates (shift-twists) the se2 kernels (planar rotation + orientation shift)\n",
        "\n",
        "\n",
        "\n",
        "In this demo we will construct the following network:\n",
        "\n",
        "| layer nr. | Layer                          | Tensor shape  |\n",
        "| --------- | ------------------------------ | ------------- |\n",
        "| 0         | input                          | (32 x 32 x 1) |\n",
        "| --------- | --------------------------------------------------- | -------------------------- |\n",
        "| 1         | 5x5 lifting convultion (+ReLU) | (28 x 28 x Ntheta x Nc)  |\n",
        "| 1         | 2x2 max pooling                | (14 x 14 x Ntheta x Nc)  |\n",
        "| --------- | --------------------------------------------------- | -------------------------- |\n",
        "| 2         | 5x5 group convultion (+ReLU)   | (10 x 10 x Ntheta x 2*Nc)  |\n",
        "| 2         | 2x2 max pooling                | (5 x 5 x Ntheta x 2*Nc)  |\n",
        "| --------- | --------------------------------------------------- | -------------------------- |\n",
        "| 3         | 5x5 2D convultion (+ReLU)      | (1 x 1 x Ntheta x 4*Nc)  |\n",
        "| --------- | --------------------------------------------------- | -------------------------- |\n",
        "| 4         | 1x1 2D convultion (+ReLU)      | (1 x 1 x Ntheta x 128)  |\n",
        "| --------- | --------------------------------------------------- | -------------------------- |\n",
        "| 5         | 1x1 2D convolution: the output layer | (10) |\n",
        "\n",
        "Here Ntheta is the number of orientation samples to discretize the SE(2) group, Nc is the number of channels in the lifting layer. The first two layers are **roto-translation covariant**, meaning that the feature vectors rotate according to rotations of the input patterns (e.g. basic features do not need to be learned for each orientation). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksa8yuFwod0U",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Part 1: Load the libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwOvDmoAod0W",
        "colab_type": "text"
      },
      "source": [
        "## Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zFnEec7Dod0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Impor tensorflow and numpy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math as m\n",
        "import time\n",
        "# For validation\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "\n",
        "# For plotting\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Import the library\n",
        "import se2cnn.layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G5j3Y_Jod0g",
        "colab_type": "text"
      },
      "source": [
        "## Useful functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzL0jHyaod0i",
        "colab_type": "text"
      },
      "source": [
        "### The se2cnn layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9AeEfk-od0j",
        "colab_type": "text"
      },
      "source": [
        "For useage of the relevant layers defined in se2cnn.layers uncomment and run the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isqEzLdfod0m",
        "colab_type": "code",
        "outputId": "191b15b3-bc41-48e6-807a-b4a0f3845210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "help(se2cnn.layers.z2_se2n)\n",
        "help(se2cnn.layers.se2n_se2n)\n",
        "help(se2cnn.layers.spatial_max_pool)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function z2_se2n in module se2cnn.layers:\n",
            "\n",
            "z2_se2n(input_tensor, kernel, orientations_nb, periodicity=6.283185307179586, diskMask=True, padding='VALID')\n",
            "    Constructs a group convolutional layer.\n",
            "    (lifting layer from Z2 to SE2N with N input number of orientations)\n",
            "    \n",
            "    INPUT:\n",
            "        - input_tensor in Z2, a tensorflow Tensor with expected shape:\n",
            "            [BatchSize, Height, Width, ChannelsIN]\n",
            "        - kernel, a tensorflow Tensor with expected shape:\n",
            "            [kernelSize, kernelSize, ChannelsIN, ChannelsOUT]\n",
            "        - orientations_nb, an integer specifying the number of rotations\n",
            "    \n",
            "    INPUT (optional):\n",
            "        - periodicity, rotate in total over 2*np.pi or np.pi\n",
            "        - disk_mask, True or False, specifying whether or not to mask the kernels spatially\n",
            "    \n",
            "    OUTPUT:\n",
            "        - output_tensor, the tensor after group convolutions with shape\n",
            "            [BatchSize, Height', Width', orientations_nb, ChannelsOut]\n",
            "            (Height', Width' are reduced sizes due to the valid convolution)\n",
            "        - kernels_formatted, the formated kernels, i.e., the full stack of rotated kernels with shape:\n",
            "            [orientations_nb, kernelSize, kernelSize, ChannelsIN, ChannelsOUT]\n",
            "\n",
            "Help on function se2n_se2n in module se2cnn.layers:\n",
            "\n",
            "se2n_se2n(input_tensor, kernel, periodicity=6.283185307179586, diskMask=True, padding='VALID')\n",
            "    Constructs a group convolutional layer.\n",
            "    (group convolution layer from SE2N to SE2N with N input number of orientations)\n",
            "    INPUT:\n",
            "        - input_tensor in SE2n, a tensor flow tensor with expected shape:\n",
            "            [BatchSize, nbOrientations, Height, Width, ChannelsIN]\n",
            "        - kernel, a tensorflow Tensor with expected shape:\n",
            "            [kernelSize, kernelSize, nbOrientations, ChannelsIN, ChannelsOUT]\n",
            "    \n",
            "    INPUT (optional):\n",
            "        - periodicity, rotate in total over 2*np.pi or np.pi\n",
            "        - disk_mask, True or False, specifying whether or not to mask the\n",
            "            kernels spatially\n",
            "    \n",
            "    OUTPUT:\n",
            "        - output_tensor, the tensor after group convolutions with shape\n",
            "            [BatchSize, Height', Width', nbOrientations, ChannelsOut]\n",
            "            (Height', Width' are the reduced sizes due to the valid convolution)\n",
            "        - kernels_formatted, the formated kernels, i.e., the full stack of\n",
            "            rotated kernels with shape [nbOrientations, kernelSize, kernelSize, nbOrientations, channelsIn, channelsOut]\n",
            "\n",
            "Help on function spatial_max_pool in module se2cnn.layers:\n",
            "\n",
            "spatial_max_pool(input_tensor, nbOrientations, padding='VALID')\n",
            "    Performs spatial max-pooling on every orientation of the SE2N tensor.\n",
            "    INPUT:\n",
            "        - input_tensor in SE2n, a tensor flow tensor with expected shape:\n",
            "            [BatchSize, Height, Width, nbOrientations, ChannelsIN]\n",
            "    \n",
            "    OUTPUT:\n",
            "        - output_tensor, the tensor after spatial max-pooling\n",
            "            [BatchSize, Height/2, Width/2, nbOrientations, ChannelsOut]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAHTd4K-od0s",
        "colab_type": "text"
      },
      "source": [
        "### Weight initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpODK5f_od0u",
        "colab_type": "text"
      },
      "source": [
        "For initialization we use the initialization method for ReLU activation functions as proposed in:\n",
        "\n",
        "He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an4S7etDod0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xavier's/He-Rang-Zhen-Sun initialization for layers that are followed ReLU\n",
        "def weight_initializer(n_in, n_out):\n",
        "    return tf.random_normal_initializer(mean=0.0, stddev=m.sqrt(2.0 / (n_in))\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vrvJbKmod03",
        "colab_type": "text"
      },
      "source": [
        "### Confusion matrix plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc7BrHcDod06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEUEz6fFod1A",
        "colab_type": "text"
      },
      "source": [
        "### Size of a tf tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcB4-sCiod1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def size_of(tensor) :\n",
        "    # Multiply elements one by one\n",
        "    result = 1\n",
        "    for x in tensor.get_shape().as_list():\n",
        "         result = result * x \n",
        "    return result "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHVI9dhsod1H",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Part 2: Load and format the MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5qnkl5Iod1I",
        "colab_type": "text"
      },
      "source": [
        "The MNIS dataset consists of 28x28 images of handwritten characters. We are going to classify each input image into 1 of the 10 classes (the digits 0 to 9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e4819a2a-62ad-4480-8ebe-adc1bb081fb3",
        "id": "FxxAk-7r4_hr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
        "train_data = mnist.train.images # Returns np.array\n",
        "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
        "valid_data = mnist.validation.images # Returns np.array\n",
        "valid_labels = np.asarray(mnist.validation.labels, dtype=np.int32)\n",
        "eval_data = mnist.test.images # Returns np.array\n",
        "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-c009531ae0cf>:1: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVmRk9xf2aN4",
        "colab_type": "code",
        "outputId": "a3b022cc-272b-4c07-89bc-a2c18da39229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(valid_data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC0AdUhWod1X",
        "colab_type": "text"
      },
      "source": [
        "By default the data is formatted as flattened arrays. Here were format them as 2D feature maps (with only 1 channel)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCjyYkkod1Z",
        "colab_type": "code",
        "outputId": "753b28dd-c467-41d2-d11b-a8b01288216b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "# Reshape to 2D multi-channel images\n",
        "train_data_2D = train_data.reshape([len(train_data),28,28,1]) # [batch_size, Nx, Ny, Nc]\n",
        "eval_data_2D = eval_data.reshape([len(eval_data),28,28,1])\n",
        "print(type(train_labels))\n",
        "# Plot the first sample\n",
        "plt.plot()\n",
        "plt.title('Digit = %d' % train_labels[0])\n",
        "plt.imshow(train_data_2D[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7cfd363668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcbNJqWod1g",
        "colab_type": "text"
      },
      "source": [
        "We would like to have the patches to be of size 32x32 such that we can reduce it to 1x1 via 5x5 convolutions and max pooling layers. So, here we pad the images on the left and right with zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS8Wzieeod1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_2D = np.pad(train_data_2D,((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=((0,0),(0,0),(0,0),(0,0)))\n",
        "eval_data_2D = np.pad(eval_data_2D,((0,0),(2,2),(2,2),(0,0)),'constant', constant_values=((0,0),(0,0),(0,0),(0,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSZVGTr0od1m",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Part 3: Build a graph (design the G-CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da7qf0aDod1n",
        "colab_type": "text"
      },
      "source": [
        "## Build a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5DIxzG4od1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = tf.Graph()\n",
        "graph.as_default()\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5ddw8Cqod1u",
        "colab_type": "text"
      },
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad2WKAYpod1x",
        "colab_type": "text"
      },
      "source": [
        "Kernel size and number of orientations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZQ5HZmpod1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ntheta = 12 # Kernel size in angular direction\n",
        "Nxy=5       # Kernel size in spatial direction\n",
        "Nc = 4      # Number of channels in the initial layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwI3M5cFod17",
        "colab_type": "text"
      },
      "source": [
        "### Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y73ImGlSod19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_ph = tf.placeholder( dtype = tf.float32, shape = [None,32,32,1] )\n",
        "labels_ph = tf.placeholder( dtype = tf.int32, shape = [None,] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acmj06pZod2I",
        "colab_type": "text"
      },
      "source": [
        "### Prepare for the first layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_QCocliod2M",
        "colab_type": "code",
        "outputId": "ca14d7b5-c721-4429-a20a-c302b8f5b64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(inputs_ph.shape)\n",
        "tensor_in = inputs_ph\n",
        "Nc_in = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-TMAhIQod2b",
        "colab_type": "text"
      },
      "source": [
        "### Save the kernels to a library for later inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IORwsefod2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kernels={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysf0h1X3od2r",
        "colab_type": "text"
      },
      "source": [
        "## Layer 1: The lifting layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIYtJwGkod2t",
        "colab_type": "code",
        "outputId": "f8b733e5-a5b7-4ae3-dcf4-74c29a65da96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "with tf.variable_scope(\"Layer_{}\".format(1)) as _scope:\n",
        "    ## Settings\n",
        "    Nc_out = Nc\n",
        "\n",
        "    ## Perform lifting convolution\n",
        "    # The kernels used in the lifting layer\n",
        "    kernels_raw = tf.get_variable(\n",
        "                        'kernel', \n",
        "                        [Nxy,Nxy,Nc_in,Nc_out],\n",
        "                        initializer=weight_initializer(Nxy*Nxy*Nc_in,Nc_out))\n",
        "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
        "    bias = tf.get_variable( # Same bias for all orientations\n",
        "                        \"bias\",\n",
        "                        [1, 1, 1, 1, Nc_out], \n",
        "                        initializer=tf.constant_initializer(value=0.01))\n",
        "    # Lifting layer\n",
        "    tensor_out, kernels_formatted = se2cnn.layers.z2_se2n(\n",
        "                            input_tensor = tensor_in,\n",
        "                            kernel = kernels_raw,\n",
        "                            orientations_nb = Ntheta)\n",
        "    # Add bias\n",
        "    tensor_out = tensor_out + bias\n",
        "    \n",
        "    ## Perform (spatial) max-pooling\n",
        "    tensor_out = se2cnn.layers.spatial_max_pool( input_tensor=tensor_out, nbOrientations=Ntheta)\n",
        "    \n",
        "    ## Apply ReLU\n",
        "    tensor_out1 = tf.nn.relu(tensor_out)\n",
        "\n",
        "    ## Prepare for the next layer\n",
        "    tensor_in = tensor_out1\n",
        "    Nc_in = Nc_out\n",
        "    \n",
        "    ## Save kernels for inspection\n",
        "    kernels[_scope.name] = kernels_formatted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z2-SE2N BASE KERNEL SHAPE: (5, 5, 1, 4)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/SE2CNN-master/se2cnn/layers.py:251: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
            "\n",
            "Z2-SE2N ROTATED KERNEL SET SHAPE: (12, 5, 5, 1, 4)\n",
            "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 28, 28, 12, 4)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/SE2CNN-master/se2cnn/layers.py:191: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05XTOu1Cod21",
        "colab_type": "code",
        "outputId": "37184d31-9e0d-416a-d8dd-f10d409f2411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor_in.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(12), Dimension(4)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myXhb5mVod27",
        "colab_type": "text"
      },
      "source": [
        "## Layer 2: SE2-conv, max-pool, relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU2xZ0jlod29",
        "colab_type": "code",
        "outputId": "643e9eef-aaaa-40df-b65a-64ceef08d42a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "with tf.variable_scope(\"Layer_{}\".format(2)) as _scope:\n",
        "    ## Settings\n",
        "    Nc_out = 2*Nc\n",
        "\n",
        "    ## Perform group convolution\n",
        "    # The kernels used in the group convolution layer\n",
        "    kernels_raw = tf.get_variable(\n",
        "                        'kernel', \n",
        "                        [Nxy,Nxy,Ntheta,Nc_in,Nc_out],\n",
        "                        initializer=weight_initializer(Nxy*Nxy*Ntheta*Nc_in,Nc_out))\n",
        "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
        "    bias = tf.get_variable( # Same bias for all orientations\n",
        "                        \"bias\",\n",
        "                        [1, 1, 1, 1, Nc_out], \n",
        "                        initializer=tf.constant_initializer(value=0.01))\n",
        "    # The group convolution layer\n",
        "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
        "                            input_tensor = tensor_in,\n",
        "                            kernel = kernels_raw)\n",
        "    tensor_out = tensor_out + bias\n",
        "    \n",
        "    ## Perform max-pooling\n",
        "    tensor_out = se2cnn.layers.spatial_max_pool( input_tensor=tensor_out, nbOrientations=Ntheta)\n",
        "    \n",
        "    ## Apply ReLU\n",
        "    tensor_out2 = tf.nn.relu(tensor_out)\n",
        "\n",
        "    ## Prepare for the next layer\n",
        "    tensor_in = tensor_out2\n",
        "    Nc_in = Nc_out\n",
        "    \n",
        "    ## Save kernels for inspection\n",
        "    kernels[_scope.name] = kernels_formatted"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE2N-SE2N BASE KERNEL SHAPE: (5, 5, 12, 4, 8)\n",
            "SE2N-SE2N ROTATED KERNEL SET SHAPE: (12, 5, 5, 12, 4, 8)\n",
            "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 10, 10, 12, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yffJ8Eod3H",
        "colab_type": "code",
        "outputId": "254c890a-8c76-4ade-d070-f669ed3505a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor_in.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(5), Dimension(5), Dimension(12), Dimension(8)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwVEhN0Kod3L",
        "colab_type": "text"
      },
      "source": [
        "## Layer 3: 2D fully connected layer (5x5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnNDR-REod3M",
        "colab_type": "code",
        "outputId": "7cedbaca-c461-4ae6-a17d-40f811d952e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# 2D convolution layer\n",
        "with tf.variable_scope(\"Layer_{}\".format(3)) as _scope:\n",
        "    ## Settings\n",
        "    Nc_out = 4*Nc\n",
        "\n",
        "    ## Perform group convolution\n",
        "    # The kernels used in the group convolution layer\n",
        "    kernels_raw = tf.get_variable(\n",
        "                    'kernel', \n",
        "                    [Nxy,Nxy,Ntheta,Nc_in,Nc_out],\n",
        "                    initializer=weight_initializer(Nxy*Nxy*Ntheta*Nc_in,Nc_out))\n",
        "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
        "    bias = tf.get_variable( # Same bias for all orientations\n",
        "                        \"bias\",\n",
        "                        [1, 1, 1, 1, Nc_out], \n",
        "                        initializer=tf.constant_initializer(value=0.01))\n",
        "    # Convolution layer\n",
        "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
        "                            input_tensor = tensor_in,\n",
        "                            kernel = kernels_raw)\n",
        "    tensor_out = tensor_out + bias\n",
        "    \n",
        "    ## Apply ReLU\n",
        "    tensor_out3 = tf.nn.relu(tensor_out)\n",
        "\n",
        "    ## Prepare for the next layer\n",
        "    tensor_in = tensor_out3\n",
        "    Nc_in = Nc_out\n",
        "    \n",
        "    ## Save kernels for inspection\n",
        "    kernels[_scope.name] = kernels_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE2N-SE2N BASE KERNEL SHAPE: (5, 5, 12, 8, 16)\n",
            "SE2N-SE2N ROTATED KERNEL SET SHAPE: (12, 5, 5, 12, 8, 16)\n",
            "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 1, 1, 12, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHmt_f2uod3S",
        "colab_type": "code",
        "outputId": "f3dff157-da8a-4814-e115-7e16fa1a9d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor_in.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(12), Dimension(16)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU9uSu_Kod3X",
        "colab_type": "text"
      },
      "source": [
        "## Layer 4: Fully connected layer (1x1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJHTk9YTod3Y",
        "colab_type": "code",
        "outputId": "c672611b-0e1f-4519-9022-40869ffd86fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# 2D convolution layer\n",
        "with tf.variable_scope(\"Layer_{}\".format(4)) as _scope:\n",
        "    ## Settings\n",
        "    Nc_out = 128\n",
        "\n",
        "    ## Perform group convolution\n",
        "    # The kernels used in the group convolution layer\n",
        "    kernels_raw = tf.get_variable(\n",
        "                    'kernel', \n",
        "                    [1,1,Ntheta,Nc_in,Nc_out],\n",
        "                    initializer=weight_initializer(1*1*Ntheta*Nc_in,Nc_out))\n",
        "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
        "    bias = tf.get_variable( # Same bias for all orientations\n",
        "                        \"bias\",\n",
        "                        [1, 1, 1, 1, Nc_out], \n",
        "                        initializer=tf.constant_initializer(value=0.01))\n",
        "    # Convolution layer\n",
        "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
        "                            input_tensor = tensor_in,\n",
        "                            kernel = kernels_raw)\n",
        "    tensor_out = tensor_out + bias\n",
        "    \n",
        "    ## Apply ReLU\n",
        "    tensor_out4 = tf.nn.relu(tensor_out)\n",
        "\n",
        "    ## Prepare for the next layer\n",
        "    tensor_in = tensor_out4\n",
        "    Nc_in = Nc_out\n",
        "    \n",
        "    ## Save kernels for inspection\n",
        "    kernels[_scope.name] = kernels_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE2N-SE2N BASE KERNEL SHAPE: (1, 1, 12, 16, 128)\n",
            "SE2N-SE2N ROTATED KERNEL SET SHAPE: (12, 1, 1, 12, 16, 128)\n",
            "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 1, 1, 12, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaESS6BDod3e",
        "colab_type": "code",
        "outputId": "652b794e-e642-4949-9d98-7691a3d57c8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor_in.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(12), Dimension(128)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esyz-qzYod3l",
        "colab_type": "text"
      },
      "source": [
        "## Layer 5: Fully connected (1x1) to output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kke8qWiOod3m",
        "colab_type": "code",
        "outputId": "34e296ec-142f-48c8-958d-a52402cfa026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "with tf.variable_scope(\"Layer_{}\".format(5)) as _scope:\n",
        "    ## Settings\n",
        "    Nc_out = 10\n",
        "\n",
        "    ## Perform group convolution\n",
        "    # The kernels used in the group convolution layer\n",
        "    kernels_raw = tf.get_variable(\n",
        "                    'kernel', \n",
        "                    [1,1,Ntheta,Nc_in,Nc_out],\n",
        "                    initializer=weight_initializer(1*1*Ntheta*Nc_in,Nc_out))\n",
        "    tf.add_to_collection('raw_kernels', kernels_raw)\n",
        "    bias = tf.get_variable( # Same bias for all orientations\n",
        "                        \"bias\",\n",
        "                        [1, 1, 1, 1, Nc_out], \n",
        "                        initializer=tf.constant_initializer(value=0.01))\n",
        "\n",
        "    \n",
        "    ## Convolution layer\n",
        "    tensor_out, kernels_formatted = se2cnn.layers.se2n_se2n(\n",
        "                            input_tensor = tensor_in,\n",
        "                            kernel = kernels_raw)\n",
        "    tensor_out5 = tensor_out + bias\n",
        "    tensor_out5 = tf.transpose(tensor_out5, [0,  4, 3, 1, 2])\n",
        "    tensor_out5 = tf.reduce_max(tensor_out5, axis=-3, keep_dims=False)\n",
        "    tensor_out5 = tf.transpose(tensor_out5, [0, 2, 3, 1])\n",
        "    logits = tensor_out5[:,0,0,:]\n",
        "    predictions = tf.argmax(input=logits, axis=1)\n",
        "    probabilities = tf.nn.softmax(logits)\n",
        "    \n",
        "    ## Save the kernels for later inspection\n",
        "    kernels[_scope.name] = kernels_raw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SE2N-SE2N BASE KERNEL SHAPE: (1, 1, 12, 128, 10)\n",
            "SE2N-SE2N ROTATED KERNEL SET SHAPE: (12, 1, 1, 12, 128, 10)\n",
            "OUTPUT SE2N ACTIVATIONS SHAPE: (?, 1, 1, 12, 10)\n",
            "WARNING:tensorflow:From <ipython-input-24-a50817d3bcd0>:24: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxzVxUJymI0J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STNc3EdBt-NX",
        "colab_type": "code",
        "outputId": "75037b61-a94a-4174-e1bb-1cb30752c29f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor_out5.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(10)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Kbykdbod3s",
        "colab_type": "code",
        "outputId": "d43ed1dc-186a-48a1-9817-26319c145b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "logits.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None), Dimension(10)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA1rpYZWuTC2",
        "colab_type": "code",
        "outputId": "a52fc001-2043-4b0d-dcaa-81282a914b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.get_shape()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([Dimension(None)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZMvG4tzod33",
        "colab_type": "text"
      },
      "source": [
        "## Define the loss and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0_gw7Bvod35",
        "colab_type": "code",
        "outputId": "4b73b370-bcd7-4b76-fccf-16f4ea6767b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Cross-entropy loss\n",
        "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels_ph, logits=logits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghcHkh6Fod3-",
        "colab_type": "code",
        "outputId": "e3a42cd4-3d9d-4501-b9f2-bdb180dfaae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#-- Define the l2 loss \n",
        "weightDecay=5e-4\n",
        "# Get the raw kernels\n",
        "variables_wd = tf.get_collection('raw_kernels')\n",
        "print('-----')\n",
        "print('RAW kernel shapes:')\n",
        "for v in variables_wd: print( \"[{}]: {}, total nr of weights = {}\".format(v.name, v.get_shape(), size_of(v)))\n",
        "print('-----')\n",
        "loss_l2 = weightDecay*sum([tf.nn.l2_loss(ker) for ker in variables_wd])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----\n",
            "RAW kernel shapes:\n",
            "[Layer_1/kernel:0]: (5, 5, 1, 4), total nr of weights = 100\n",
            "[Layer_2/kernel:0]: (5, 5, 12, 4, 8), total nr of weights = 9600\n",
            "[Layer_3/kernel:0]: (5, 5, 12, 8, 16), total nr of weights = 38400\n",
            "[Layer_4/kernel:0]: (1, 1, 12, 16, 128), total nr of weights = 24576\n",
            "[Layer_5/kernel:0]: (1, 1, 12, 128, 10), total nr of weights = 15360\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHldSVPeod4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure the Training Op (for TRAIN mode)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "\n",
        "train_op = optimizer.minimize(\n",
        "    loss=loss + loss_l2,\n",
        "    global_step=tf.train.get_global_step())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGm5zcSNod4M",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Part 4: Train and test the G-CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64bSn2QSod4O",
        "colab_type": "text"
      },
      "source": [
        "## Begin session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63PaH1v1od4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-- Start the (GPU) session\n",
        "initializer = tf.global_variables_initializer()\n",
        "session = tf.Session(graph=tf.get_default_graph()) #-- Session created\n",
        "session.run(initializer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuisa6zPod4V",
        "colab_type": "text"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meb47ESOod4Z",
        "colab_type": "text"
      },
      "source": [
        "In each epoch we pass over all input samples in batch sizes of batch_size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XWPfEULod4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=100\n",
        "n_epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysW7J30Hod4g",
        "colab_type": "text"
      },
      "source": [
        "Loop over the input stack in batch of size \"batch_size\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgiiwRPood4h",
        "colab_type": "code",
        "outputId": "4bce3c53-50fa-430f-cef5-a3972b82968e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for epoch_nr in range(n_epochs):\n",
        "    loss_average = 0\n",
        "    data = train_data_2D\n",
        "    labels = train_labels\n",
        "    # KBatch settings\n",
        "    NItPerEpoch = m.floor(len(data)/batch_size) #number of iterations per epoch\n",
        "    samples=np.random.permutation(len(data))\n",
        "    # Loop over dataset\n",
        "    tStart = time.time()\n",
        "    for iteration in range(NItPerEpoch):\n",
        "        feed_dict = {\n",
        "                inputs_ph: np.array(data[samples[iteration*batch_size:(iteration+1)*batch_size]]),\n",
        "                labels_ph: np.array(labels[samples[iteration*batch_size:(iteration+1)*batch_size]])\n",
        "                }\n",
        "        operators_output = session.run([ loss , train_op ], feed_dict)\n",
        "        loss_average += operators_output[0]/NItPerEpoch\n",
        "    tElapsed = time.time() - tStart\n",
        "    print('Epoch ' , epoch_nr , ' finished... Average loss = ' , round(loss_average,4) , ', time = ',round(tElapsed,4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0  finished... Average loss =  0.2871 , time =  377.4943\n",
            "Epoch  1  finished... Average loss =  0.0701 , time =  377.337\n",
            "Epoch  2  finished... Average loss =  0.0506 , time =  374.3888\n",
            "Epoch  3  finished... Average loss =  0.0412 , time =  372.6056\n",
            "Epoch  4  finished... Average loss =  0.038 , time =  377.4034\n",
            "Epoch  5  finished... Average loss =  0.0332 , time =  375.4972\n",
            "Epoch  6  finished... Average loss =  0.0329 , time =  380.5346\n",
            "Epoch  7  finished... Average loss =  0.0282 , time =  384.7814\n",
            "Epoch  8  finished... Average loss =  0.0277 , time =  380.0204\n",
            "Epoch  9  finished... Average loss =  0.0275 , time =  380.9766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBvMgz3Jod4m",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqDfZQ7HLnBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-EmSmJgod4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1000\n",
        "labels_pred = []\n",
        "for i in range(round(len(eval_data_2D)/batch_size)):\n",
        "    [ labels_pred_batch ] = session.run([ predictions ], { inputs_ph: eval_data_2D[i*batch_size:(i+1)*batch_size] })\n",
        "    labels_pred = labels_pred + list(labels_pred_batch)\n",
        "labels_pred = np.array(labels_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L794jANFod4w",
        "colab_type": "text"
      },
      "source": [
        "Compare the first 10 results with the ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGy4xLHLod4y",
        "colab_type": "code",
        "outputId": "ceea9727-630f-4bf8-effe-455e09dc693c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(labels_pred[0:10])\n",
        "print(eval_labels[0:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1 0 4 1 4 9 6 9]\n",
            "[7 2 1 0 4 1 4 9 5 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vQ6kt-pod5C",
        "colab_type": "text"
      },
      "source": [
        "The accuracy (average nr of successes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZNDd0wHod5F",
        "colab_type": "code",
        "outputId": "279c3f4f-a6c4-4dea-d662-1e92f413eb61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((labels_pred - eval_labels)**2==0).astype(float).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9895"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p7QT1b9od5N",
        "colab_type": "text"
      },
      "source": [
        "Total nr of errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc2d-azlod5S",
        "colab_type": "code",
        "outputId": "ada6b9da-870f-4a93-fed3-0ded25150227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((labels_pred - eval_labels)**2>0).astype(float).sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYiqnD20od5c",
        "colab_type": "text"
      },
      "source": [
        "Error rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQyWOeSsod5e",
        "colab_type": "code",
        "outputId": "b698f8e0-4ddf-4ee2-9938-1fa0e312d1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "100*((labels_pred - eval_labels)**2>0).astype(float).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMxz04y7od5l",
        "colab_type": "text"
      },
      "source": [
        "Plot a confusion matrix to see what kind of errors are made"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EuSAqkE4od5n",
        "colab_type": "code",
        "outputId": "61b26adc-454e-4df1-dc9c-6d8124f8a91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "cm = confusion_matrix(eval_labels, labels_pred)\n",
        "plot_confusion_matrix(cm, range(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}